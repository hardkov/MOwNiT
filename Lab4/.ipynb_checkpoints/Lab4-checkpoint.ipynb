{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 4 Singular Value Decomposition\n",
    "### Autor: Krzysztof Hardek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zad 1 Wyszukiwarka\n",
    "### 1 Duży zbiór dokumentów tekstowych\n",
    "Korzystam z api wikipedii dla pythona 3. Zajego pomocą wyszukuje około 1100 stron z kategorii muzyka oraz odpowiendio przetwarzam ich zawartość. Funkcja parse_content filtruje Stringa w taki sposób, aby przy grupowaniu stringi typu \"Terrordrome\" oraz \"Terrordrome;\" były traktowane jako to samo słowo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "\n",
    "def parse_content(content):\n",
    "    content = content.replace('.', '')\n",
    "    content = content.replace(',', '')\n",
    "    content = content.replace('(', '')\n",
    "    content = content.replace(')', '')\n",
    "    content = content.replace(':', '')\n",
    "    content = content.replace('-', ' ')\n",
    "    content = content.replace('\\n', ' ')\n",
    "    content = content.replace('\"', '')\n",
    "    content = content.replace(';', '')\n",
    "    content = content.replace('==', '')\n",
    "    content = content.replace('–', ' ')\n",
    "    content = content.replace('”', '')\n",
    "    content = content.replace('„', '')\n",
    "    content = content.replace('?', '') # questionable\n",
    "    content = content.replace('!', '') # questionable\n",
    "    return content\n",
    "\n",
    "\n",
    "def valid_page(title):\n",
    "    if 'Category' not in title and 'Wikipedia' not in title and \"List\" not in title:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def fill_list(categorymembers, list, level=0, max_level=1):\n",
    "    for c in categorymembers.values():\n",
    "        if valid_page(c.title):\n",
    "            list.append(c.title)\n",
    "        if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level:\n",
    "            fill_list(c.categorymembers, list, level=level + 1, max_level=max_level)\n",
    "\n",
    "cat = wiki.page('Category:Physics')\n",
    "document_titles = []\n",
    "fill_list(cat.categorymembers, document_titles)\n",
    "\n",
    "document_titles = document_titles[:1010]  #cutting list in order to improve execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Słownik słów kluczowych (termów)\n",
    "Term jest pythonowym słownikiem. Są tam skojarzone ze sobą słowo oraz jego indeks w później tworzonych wektorach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = {}\n",
    "term_idx = 0\n",
    "\n",
    "for doc in document_titles:\n",
    "    content = wiki.page(doc).text\n",
    "    content = parse_content(content)\n",
    "    content_list = content.split()\n",
    "    for word in content_list:\n",
    "        if word not in term:\n",
    "            term[word] = term_idx\n",
    "            term_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Wyznaczenie wektorów cech bag-of-words. \n",
    "Wektor $ d_j $ jest reprezentowany przez bags_of_words[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_of_words = np.zeros((len(document_titles), len(term)))\n",
    "\n",
    "\n",
    "for doc_idx, doc in enumerate(document_titles):\n",
    "    content = wiki.page(doc).text\n",
    "    content = parse_content(content)\n",
    "    content_list = content.split()\n",
    "    for word in content_list:\n",
    "        word_idx = term[word] \n",
    "        bags_of_words[doc_idx][word_idx] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4  Zbudowanie rzadkiej macierzy wektorów cech term-by-document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_by_doc = bags_of_words.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Wstępne przetworzenie zbioru danych przez inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_count(vec):\n",
    "    counter = 0\n",
    "    for i in range(len(vec)):\n",
    "        if vec[i] > 0:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "N = len(document_titles)\n",
    "\n",
    "for term_idx in range(len(term_by_doc)):\n",
    "    n_w = doc_count(term_by_doc[term_idx])\n",
    "    IDF = np.log(N/n_w)\n",
    "    for doc_idx in range(len(term_by_doc[term_idx])):\n",
    "        term_by_doc[term_idx][doc_idx] *= IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Funkcja pozwalająca na wprowadzenie zapytania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fractal dimension', 'Fractal analysis', 'Nuclear fusion']\n"
     ]
    }
   ],
   "source": [
    "def similar_docs(word_list, k, similarity_measure, term_by_doc):\n",
    "    q = np.zeros((len(term_by_doc)))\n",
    "    similarity_vec = np.zeros((len(document_titles)))\n",
    "    docs_names = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word in term:\n",
    "            term_idx = term[word]\n",
    "            q[term_idx] += 1\n",
    "            \n",
    "    for doc_idx in range(len(document_titles)):\n",
    "        d = term_by_doc[:, doc_idx]\n",
    "        similarity_vec[doc_idx] = similarity_measure(q, d)\n",
    "    \n",
    "    indexes = sorted(range(len(similarity_vec)), key = lambda i: similarity_vec[i])[-k:]\n",
    "    \n",
    "    for idx in indexes:\n",
    "        docs_names.insert(0, document_titles[idx])\n",
    "        \n",
    "    return docs_names\n",
    "\n",
    "\n",
    "def similarity_measure1(q, d):\n",
    "    q_arr = np.array(q)\n",
    "    q_T = q_arr.transpose()\n",
    "    \n",
    "    if q_T.dot(d) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return q_T.dot(d) / (np.linalg.norm(q) * np.linalg.norm(d))\n",
    "\n",
    "\n",
    "docs_names = similar_docs([\"patricle\", \"fusion\", \"fractal\"], 3, similarity_measure1, term_by_doc)\n",
    "print(docs_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7  Użycie zmodyfikowanej miary prawdopodobienstwa, korzystającej z wektorów znormalizowanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fractal dimension', 'Fractal analysis', 'Nuclear fusion']\n"
     ]
    }
   ],
   "source": [
    "def normalize(d):\n",
    "    if(np.linalg.norm(d) == 0):\n",
    "        return np.zeros(len(d))\n",
    "    \n",
    "    return d/np.linalg.norm(d)\n",
    "\n",
    "\n",
    "def similarity_measure2(q, d):\n",
    "    q_n = normalize(q)\n",
    "    d_n = normalize(d)\n",
    "    q_n = np.array(q_n)\n",
    "    q_n_T = q_n.transpose()\n",
    "    if q_n_T.dot(d_n) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return abs(q_n_T.dot(d_n)) # abs probably redundant \n",
    "\n",
    "    \n",
    "docs_names = similar_docs([\"particle\", \"fusion\", \"fractal\"], 3, similarity_measure2, term_by_doc)\n",
    "print(docs_names)\n",
    "m = np.random.rand(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Usuwanie szumu z macierzy term_by_doc za pomocą SVD oraz low rank approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_rank_appr(A, k):\n",
    "    u, s, v = np.linalg.svd(A, full_matrices=False,)\n",
    "    return  np.matrix(u[:, :k]) * np.diag(s[:k]) * np.matrix(v[:k, :])\n",
    "\n",
    "\n",
    "clean_term_by_doc = low_rank_appr(term_by_doc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 Porównanie działania funkcji bez szumu oraz z szumem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quantum mechanics', 'Hydrodynamic quantum analogs', 'Transactional interpretation']\n",
      "['Quantum mechanics', 'Refraction', 'Matter wave clock']\n"
     ]
    }
   ],
   "source": [
    "docs_names_clean = similar_docs([\"particle\", \"quantum\", \"wave\", \"air\", \"water\", \"equation\"], 3, similarity_measure2, clean_term_by_doc)\n",
    "docs_names = similar_docs([\"particle\", \"quantum\", \"wave\", \"air\", \"water\", \"equation\"], 3, similarity_measure2, term_by_doc)\n",
    "print(docs_names_clean)\n",
    "print(docs_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym wyszukiwaniu starałem sie wyszukać strony związane jak najbardziej z mechaniką kwantową. Słowa air oraz water są mało adekwatne do tematu. Widać, że przy redukcji szumu mają one mniejszy wpływ na wyszukanie i wyniki są bardziej związanie z tematem głównym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quantum mechanics', 'Transactional interpretation', 'Heisenberg cut']\n",
      "['Quantum mechanics', 'Matter wave clock', 'Refraction']\n"
     ]
    }
   ],
   "source": [
    "docs_names_clean = similar_docs([\"particle\", \"quantum\", \"wave\", \"stone\", \"water\", \"equation\"], 3, similarity_measure2, clean_term_by_doc)\n",
    "docs_names = similar_docs([\"particle\", \"quantum\", \"wave\", \"stone\", \"water\", \"equation\"], 3, similarity_measure2, term_by_doc)\n",
    "print(docs_names_clean)\n",
    "print(docs_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogiczna sytuacja. Słowa stone oraz water kompletnie nie pasują. Redukcja szumu to wyłapuje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quantum mechanics', 'Matter wave clock', 'Transactional interpretation']\n",
      "['Quantum mechanics', 'Invariant mass', 'Matter wave clock']\n"
     ]
    }
   ],
   "source": [
    "docs_names_clean = similar_docs([\"particle\", \"quantum\", \"wave\", \"mass\", \"speed\", \"equation\"], 3, similarity_measure2, clean_term_by_doc)\n",
    "docs_names = similar_docs([\"particle\", \"quantum\", \"wave\", \"mass\", \"speed\", \"equation\"], 3, similarity_measure2, term_by_doc)\n",
    "print(docs_names_clean)\n",
    "print(docs_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym przypadku obydwa wyszukania są na podobnym poziomie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalna wartość k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quantum mechanics', 'Matter wave clock', 'Transactional interpretation', 'Copenhagen interpretation', 'Heisenberg cut', 'Hydrodynamic quantum analogs', 'Observer effect (physics)', 'Interpretations of quantum mechanics', 'Classical physics', 'History of quantum mechanics', 'Observer (quantum physics)', 'John Stewart Bell Prize', 'The Principles of Quantum Mechanics', 'Faster-than-light', 'Koopman–von Neumann classical mechanics', 'Schrödinger–Newton equation', 'Coherence (physics)', 'Quantization (physics)', 'Branches of physics', 'Quantum potential', 'Speed of light', 'The Physical Principles of the Quantum Theory', 'Action at a distance', 'Philosophy of physics', 'U-bit', 'Über quantentheoretische Umdeutung kinematischer und mechanischer Beziehungen', 'Quantum non-equilibrium', 'Mathematical formulation of quantum mechanics', 'Relational approach to quantum physics', 'Quantum number']\n",
      "['Quantum mechanics', 'Invariant mass', 'Matter wave clock', 'Speed of light', 'Schrödinger–Newton equation', 'Point particle', 'Negative mass', 'Quantum potential', 'Copenhagen interpretation', 'Refraction', 'Faster-than-light', 'Relativistic wave equations', 'Mass formula', 'History of quantum field theory', 'Observer effect (physics)', 'Mass-to-charge ratio', 'Classical mechanics', 'Speed of gravity', 'Interpretations of quantum mechanics', 'Free particle', 'Relational approach to quantum physics', 'Wave function collapse', \"Einstein's thought experiments\", \"Einstein's thought experiments\", 'Quantum number', 'Electromagnetic mass', 'Wave equation', 'Branches of physics', 'Heisenberg cut', 'Old quantum theory']\n"
     ]
    }
   ],
   "source": [
    "docs_names_clean = similar_docs([\"particle\", \"quantum\", \"wave\", \"mass\", \"speed\", \"equation\"], 30, similarity_measure2, clean_term_by_doc)\n",
    "docs_names = similar_docs([\"particle\", \"quantum\", \"wave\", \"mass\", \"speed\", \"equation\"], 30, similarity_measure2, term_by_doc)\n",
    "print(docs_names_clean)\n",
    "print(docs_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wydaje mi się że od około k = 20 wśród ostatnich wyszukań zaczynają pojawiać się mniej adekwatne strony. Uważam więc, że dla takich liczb (1000 dokumentów, 6 słów klucz), zwracanie kilkunastu najbardziej odpowiadających dokumentów będzie rozsądną decyzją. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
